{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Theoretical Questions**"
      ],
      "metadata": {
        "id": "HjsYHVOakLWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Question 1: What is a Decision Tree, and how does it work?\n",
        "Answer 1: A Decision Tree is a supervised learning model that splits data into branches to predict outcomes by learning decision rules from features.\n",
        "\n",
        "Question 2: What are impurity measures in Decision Trees?\n",
        "Answer 2: Impurity measures quantify how mixed the classes are in a node. Common measures: Gini Impurity and Entropy.\n",
        "\n",
        "Question 3: What is the mathematical formula for Gini Impurity?\n",
        "Answer 3: Gini = 1 - ∑(pi²), where pi is the probability of class i in the node.\n",
        "\n",
        "Question 4: What is the mathematical formula for Entropy?\n",
        "Answer 4: Entropy = - ∑(pi * log₂(pi)), where pi is the probability of class i in the node.\n",
        "\n",
        "Question 5: What is Information Gain, and how is it used in Decision Trees?\n",
        "Answer 5: Information Gain measures the reduction in impurity. It's used to choose the best feature for splitting.\n",
        "\n",
        "Question 6: What is the difference between Gini Impurity and Entropy?\n",
        "Answer 6: Gini is faster and favors larger partitions; Entropy is more informative but computationally heavier.\n",
        "\n",
        "Question 7: What is the mathematical explanation behind Decision Trees?\n",
        "Answer 7: Decision Trees use recursive binary splitting, selecting features that maximize Information Gain or minimize Gini Impurity.\n",
        "\n",
        "Question 8: What is Pre-Pruning in Decision Trees?\n",
        "Answer 8: Pre-pruning stops tree growth early using conditions like max depth or min samples.\n",
        "\n",
        "Question 9: What is Post-Pruning in Decision Trees?\n",
        "Answer 9: Post-pruning removes branches from a fully grown tree to reduce overfitting.\n",
        "\n",
        "Question 10: What is the difference between Pre-Pruning and Post-Pruning?\n",
        "Answer 10: Pre-pruning prevents overfitting during training; post-pruning simplifies the tree after full growth.\n",
        "\n",
        "Question 11: What is a Decision Tree Regressor?\n",
        "Answer 11: It is a Decision Tree model used for predicting continuous values instead of classes.\n",
        "\n",
        "Question 12: What are the advantages and disadvantages of Decision Trees?\n",
        "Answer 12:\n",
        "Advantages: Easy to interpret, no need for feature scaling.\n",
        "Disadvantages: Prone to overfitting, unstable to small data changes.\n",
        "\n",
        "Question 13: How does a Decision Tree handle missing values?\n",
        "Answer 13: It can use surrogate splits or assign missing data based on most frequent values.\n",
        "\n",
        "Question 14: How does a Decision Tree handle categorical features?\n",
        "Answer 14: It splits categories based on impurity reduction, using one-hot encoding or grouping.\n",
        "\n",
        "Question 15: What are some real-world applications of Decision Trees?\n",
        "Answer 15: Fraud detection, loan approval, medical diagnosis, customer segmentation."
      ],
      "metadata": {
        "id": "CkM1AsJBkKze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Practical Question**"
      ],
      "metadata": {
        "id": "Qo4iJQITkKwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 16: Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy"
      ],
      "metadata": {
        "id": "L_4HzILdkhBK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c_0aKMpj-nV"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 17: Train a Decision Tree Classifier using Gini Impurity and print the feature importances"
      ],
      "metadata": {
        "id": "FE4VAxlpkiCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier(criterion='gini')\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Feature importances:\", model.feature_importances_)\n"
      ],
      "metadata": {
        "id": "U3alD9BwkhSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 18: Train a Decision Tree Classifier using Entropy and print the model accuracy"
      ],
      "metadata": {
        "id": "O1zlw62uki5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier(criterion='entropy')\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "uQmUSj9SkjDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 19: Train a Decision Tree Regressor on a housing dataset and evaluate using MSE"
      ],
      "metadata": {
        "id": "aF730lC5kjMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "regressor = DecisionTreeRegressor()\n",
        "regressor.fit(X_train, y_train)\n",
        "print(\"MSE:\", mean_squared_error(y_test, regressor.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "or1M5x_NkjWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 20: Visualize the tree using graphviz"
      ],
      "metadata": {
        "id": "mQ5PKSvmkkBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "dot_data = export_graphviz(model, out_file=None, feature_names=load_iris().feature_names, class_names=load_iris().target_names)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"iris_tree\", view=True)  # Will open a PDF\n"
      ],
      "metadata": {
        "id": "FJi4UZ_WkkKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 21: Train a Decision Tree Classifier with max_depth=3 and compare with fully grown tree"
      ],
      "metadata": {
        "id": "aeMAu3pAkkTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_limited = DecisionTreeClassifier(max_depth=3)\n",
        "model_limited.fit(X_train, y_train)\n",
        "acc_limited = accuracy_score(y_test, model_limited.predict(X_test))\n",
        "\n",
        "model_full = DecisionTreeClassifier()\n",
        "model_full.fit(X_train, y_train)\n",
        "acc_full = accuracy_score(y_test, model_full.predict(X_test))\n",
        "\n",
        "print(\"Limited Depth Accuracy:\", acc_limited)\n",
        "print(\"Full Tree Accuracy:\", acc_full)\n"
      ],
      "metadata": {
        "id": "qeWvfl0qkksp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 22: Train using min_samples_split=5 and compare with default"
      ],
      "metadata": {
        "id": "GXmEggFBkk1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_default = DecisionTreeClassifier()\n",
        "model_split = DecisionTreeClassifier(min_samples_split=5)\n",
        "\n",
        "model_default.fit(X_train, y_train)\n",
        "model_split.fit(X_train, y_train)\n",
        "\n",
        "print(\"Default Accuracy:\", accuracy_score(y_test, model_default.predict(X_test)))\n",
        "print(\"min_samples_split=5 Accuracy:\", accuracy_score(y_test, model_split.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ADuqg0iBkk-X",
        "outputId": "f3c0e91c-5eab-4341-e62a-750fd246e448"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DecisionTreeClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fb68bdc477b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_default\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 23: Apply feature scaling before training and compare accuracy"
      ],
      "metadata": {
        "id": "G-M1G-OBlROu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_scaled, y, random_state=0)\n",
        "\n",
        "model_scaled = DecisionTreeClassifier()\n",
        "model_scaled.fit(X_train_s, y_train_s)\n",
        "\n",
        "print(\"Unscaled Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n",
        "print(\"Scaled Accuracy:\", accuracy_score(y_test_s, model_scaled.predict(X_test_s)))\n"
      ],
      "metadata": {
        "id": "UPPfN-OuklPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 24: Train using One-vs-Rest (OvR) strategy"
      ],
      "metadata": {
        "id": "fO4alBg-lRw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "ovr_model = OneVsRestClassifier(DecisionTreeClassifier())\n",
        "ovr_model.fit(X_train, y_train)\n",
        "print(\"OvR Accuracy:\", accuracy_score(y_test, ovr_model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "LhJG3HI0klhR",
        "outputId": "26484dec-d285-4be2-b471-81ae3a2896ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DecisionTreeClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-02f7afe32ec9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0movr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0movr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OvR Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0movr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 25: Display feature importance scores"
      ],
      "metadata": {
        "id": "5iDDK1T4lSd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Feature importances:\", model.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "a4Fl2e1NlvQ7",
        "outputId": "1821a4ac-046a-4053-fb03-09338168051b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d45efd1f3405>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Feature importances:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 26: Train Regressor with max_depth=5 and compare with unrestricted"
      ],
      "metadata": {
        "id": "S6pW3g28lvln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_limited = DecisionTreeRegressor(max_depth=5)\n",
        "reg_full = DecisionTreeRegressor()\n",
        "\n",
        "reg_limited.fit(X_train, y_train)\n",
        "reg_full.fit(X_train, y_train)\n",
        "\n",
        "print(\"MSE limited:\", mean_squared_error(y_test, reg_limited.predict(X_test)))\n",
        "print(\"MSE full:\", mean_squared_error(y_test, reg_full.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "zxk_0IFklvvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 27: Apply Cost Complexity Pruning (CCP) and visualize effect"
      ],
      "metadata": {
        "id": "-zsuCdkilv4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = model.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "\n",
        "accuracies = []\n",
        "for ccp in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(ccp_alpha=ccp)\n",
        "    clf.fit(X_train, y_train)\n",
        "    accuracies.append(accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(ccp_alphas, accuracies)\n",
        "plt.xlabel(\"ccp_alpha\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"CCP Pruning Effect\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ZVVBejzGlwBZ",
        "outputId": "6a7d9dd0-bcb6-440c-8f81-53bcde589669"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-398373e7728b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_complexity_pruning_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mccp_alphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mccp_alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mccp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mccp_alphas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 28: Evaluate using Precision, Recall, and F1-Score"
      ],
      "metadata": {
        "id": "wUoNxcKKlwKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n"
      ],
      "metadata": {
        "id": "3uoJVuaklwUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "Question 29: Visualize confusion matrix using seaborn"
      ],
      "metadata": {
        "id": "TuTeVtcplweK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_test, model.predict(X_test))\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ki2Bfhshlwvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 30: Use GridSearchCV to find optimal max_depth and min_samples_split"
      ],
      "metadata": {
        "id": "aiabiHQ0lw9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'max_depth': [2, 3, 4, 5], 'min_samples_split': [2, 5, 10]}\n",
        "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", accuracy_score(y_test, grid.best_estimator_.predict(X_test)))\n"
      ],
      "metadata": {
        "id": "r2U2dEndlxKY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}